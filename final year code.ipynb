{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d101c70a",
   "metadata": {},
   "source": [
    "# wellcome to notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90534627",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mEnvRLforClassification\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import EnvRLforClassification\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d667b82",
   "metadata": {},
   "source": [
    "### set image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936135fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b56fdc",
   "metadata": {},
   "source": [
    "###  loan data function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "def get_data(path):\n",
    "    data = list()\n",
    "    for label in labels:\n",
    "        image_dir = os.path.join(path, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(image_dir):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(image_dir, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_array = cv2.resize(img_arr, (image_size, image_size))\n",
    "                data.append([resized_array, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)\n",
    "\n",
    "train = get_data('chest_xray/chest_xray/train')\n",
    "test = get_data('chest_xray/chest_xray/test')\n",
    "val = get_data('chest_xray/chest_xray/val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c950f",
   "metadata": {},
   "source": [
    "### lets generate data\n",
    "\n",
    "### help function to create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seperate_feature_and_label(dataset):\n",
    "    \"\"\" seperate target and feature values\"\"\"\n",
    "    \n",
    "    X, Y = list(), list()\n",
    "    for x, y in dataset:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    \"\"\" to normalize the data\"\"\"\n",
    "    \n",
    "    return np.array(X)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9317e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(X, Y, fig_size):\n",
    "    \"\"\" TO resize the data\"\"\"\n",
    "    \n",
    "    X = X.reshape(-1, fig_size[0], fig_size[1], 1)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cd8b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_agumentation(datagen=None):\n",
    "    \"\"\"\n",
    "    This function first check, is the data is dataGen object and than process.\n",
    "    \"\"\"\n",
    "    \n",
    "    if datagen is None:\n",
    "        return ImageDataGenerator(\n",
    "            featurewise_center = False,\n",
    "            samplewise_center = False,\n",
    "            featurewise_std_normalization = False,\n",
    "            samplewise_std_normalization = False,\n",
    "            zca_whitening = False,\n",
    "            rotation_range = 30)\n",
    "    else:\n",
    "        return datagen\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc1106",
   "metadata": {},
   "source": [
    "### lets apply all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = seperate_feature_and_label(train)\n",
    "X_test, y_test = seperate_feature_and_label(test)\n",
    "\n",
    "# lets apply normalization function\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "X_train, y_train = reshape(X_train, y_train, (image_size, image_size))\n",
    "X_test, y_test = reshape(X_test, y_test, (image_size, image_size))\n",
    "x_train = X_train\n",
    "x_test=X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datagenerator = data_agumentation(None)\n",
    "#datagenerator.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f616b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train\n",
    "y = y_train\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "input_shape = (X.shape[1],X.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837adfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the enviroment\n",
    "env = gym.make('EnvRLforClassification:RLClassification-v0')\n",
    "\n",
    "# Fill values\n",
    "env.init_dataset(X,y,batch_size=batch_size,output_shape=input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4cfdbc",
   "metadata": {},
   "source": [
    "## parameters of RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c8e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of RL\n",
    "valid_actions = env.action_space\n",
    "num_actions = valid_actions.n\n",
    "epsilon = .1  # exploration\n",
    "num_episodes = 400  #best test\n",
    "iterations_episode = 100\n",
    "\n",
    "decay_rate = 0.99\n",
    "gamma = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c4ca8",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f18e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                activation='relu',\n",
    "                input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(BatchNormalization())               # add new\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723b849b",
   "metadata": {},
   "source": [
    "####\n",
    "#### model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#### model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#### model.add(Dropout(0.25))\n",
    "\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86783be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) #128\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_actions, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f949bf1",
   "metadata": {},
   "source": [
    "# Training the the RL agent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d0ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_chain = []\n",
    "loss_chain = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df86f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_episodes):\n",
    "    loss = 0.\n",
    "    total_reward_by_episode = 0\n",
    "    # Reset enviromet, actualize the data batch\n",
    "    states = env.reset()\n",
    "\n",
    "    done = False\n",
    "\n",
    "    # Define exploration to improve performance\n",
    "    exploration = 1\n",
    "    # Iteration in one episode\n",
    "    q = np.zeros([batch_size,num_actions])\n",
    "   \n",
    "    i_iteration = 0\n",
    "    while not done:\n",
    "        i_iteration += 1\n",
    "\n",
    "        # get next action\n",
    "        if exploration > 0.001:\n",
    "            exploration = epsilon*decay_rate**(epoch*i_iteration)            \n",
    "\n",
    "        if np.random.rand() <= exploration:\n",
    "            actions = np.random.randint(0, num_actions,batch_size)\n",
    "        else:\n",
    "            q = model.predict(states)\n",
    "            actions = np.argmax(q,axis=1)\n",
    "\n",
    "        # apply actions, get rewards and new state\n",
    "        next_states, reward, done, _ = env.step(actions)\n",
    "\n",
    "        done = done[-1]\n",
    "        next_states = next_states\n",
    "        \n",
    "        q_prime = model.predict(next_states)\n",
    "\n",
    "        indx = np.argmax(q_prime,axis=1)\n",
    "        sx = np.arange(len(indx))\n",
    "        # Update q values\n",
    "        targets = reward + gamma * q[sx,indx]   \n",
    "        q[sx,actions] = targets\n",
    "\n",
    "        # Train network, update loss\n",
    "        loss += model.train_on_batch(states, q)[0]\n",
    "\n",
    "        # Update the state\n",
    "        states = next_states\n",
    "        #print(reward)\n",
    "        total_reward_by_episode += int(sum(reward))\n",
    "\n",
    "    if next_states.shape[0] != batch_size:\n",
    "            break # finished df\n",
    "    reward_chain.append(total_reward_by_episode)    \n",
    "    loss_chain.append(loss)\n",
    "\n",
    "    print(\"\\rEpoch {:03d}/{:03d} | Loss {:4.4f} |  Rewards {:03d} \".format(epoch,\n",
    "          num_episodes ,loss, total_reward_by_episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f68317",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"24-4modelChest\"+str(num_episodes)\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f486ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d676739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
